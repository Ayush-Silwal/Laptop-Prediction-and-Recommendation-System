{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00c16220-1195-4b5d-946a-c52c88fd7ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "\n",
      "Training custom Random Forest...\n",
      "\n",
      "Random Forest Performance:\n",
      "MSE: 0.1571\n",
      "MAE: 0.3212\n",
      "R² Score: 0.5923\n",
      "\n",
      "Training custom KNN...\n",
      "\n",
      "KNN Performance:\n",
      "MSE: 0.0704\n",
      "MAE: 0.1964\n",
      "R² Score: 0.8174\n",
      "\n",
      "Saving models...\n",
      "Saved successfully to laptop_models.pkl ✅\n",
      "\n",
      "Testing generic recommendation system...\n",
      "\n",
      "Student laptop recommendations under 50000:\n",
      "    Company            TypeName  Ram  SSD  Weight      Price  FeatureScore  \\\n",
      "783  Lenovo            Notebook    8    0     2.2  30,371.57      0.503721   \n",
      "364  Lenovo            Notebook    8    0     2.2  33,750.46      0.503721   \n",
      "527  Lenovo            Notebook    8    0     2.2  33,750.46      0.503721   \n",
      "677      HP  2 in 1 Convertible    8    0     1.4  34,575.56      0.543621   \n",
      "634    Asus            Notebook    8    0     2.0  34,455.00      0.513696   \n",
      "\n",
      "     PriceScore  CombinedScore  \n",
      "783    1.000000       0.751860  \n",
      "364    0.827854       0.665787  \n",
      "527    0.827854       0.665787  \n",
      "677    0.785817       0.664719  \n",
      "634    0.791959       0.652827  \n",
      "\n",
      "Premium laptop recommendations under 100000:\n",
      "⚠️ No laptops within budget 100,000.00. Showing closest options:\n",
      "    Company TypeName  Ram  SSD  Weight  PredictedPrice\n",
      "659    Dell   Gaming   32    0    4.42    96892.070376\n",
      "723    Dell   Gaming   32    0    4.36    96811.927065\n",
      "955    Dell   Gaming   16    0    4.36    95327.718537\n",
      "830   Razer   Gaming   32    0    3.49   108409.352479\n",
      "196   Razer   Gaming   32    0    3.49   108409.352479\n",
      "\n",
      "Budget gaming laptop under 70000:\n",
      "⚠️ No laptops within budget 70,000.00. Showing closest options:\n",
      "        Company   TypeName  Ram  SSD  Weight  PredictedPrice\n",
      "1117      Razer  Ultrabook    8    0    1.25    69982.799569\n",
      "458   Microsoft  Ultrabook    8    0    1.25    70109.215894\n",
      "926      Lenovo  Ultrabook    8    0    1.36    69852.823011\n",
      "649      Lenovo  Ultrabook    8    0    1.36    69852.823011\n",
      "768     Samsung  Ultrabook    8    0    1.31    70183.968657\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import heapq\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.utils import resample\n",
    "from scipy.sparse import issparse\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# ====================== CUSTOM MODELS ======================\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, (pd.Series, pd.DataFrame)):\n",
    "            y = y.values\n",
    "            \n",
    "        self.tree_ = self._build_tree(X, y, depth=0)\n",
    "    \n",
    "    def _build_tree(self, X, y, depth):\n",
    "        num_samples = X.shape[0]\n",
    "        \n",
    "        # Stopping conditions\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or \\\n",
    "           num_samples < self.min_samples_split or \\\n",
    "           len(np.unique(y)) == 1:\n",
    "            return np.mean(y)\n",
    "\n",
    "        best_split = self._find_best_split(X, y)\n",
    "        if best_split is None:\n",
    "            return np.mean(y)\n",
    "        \n",
    "        left_indices = X[:, best_split['feature']] <= best_split['value']\n",
    "        right_indices = ~left_indices\n",
    "        \n",
    "        if np.sum(left_indices) == 0 or np.sum(right_indices) == 0:\n",
    "            return np.mean(y)\n",
    "        \n",
    "        left_tree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_tree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "        \n",
    "        return {\n",
    "            'feature': best_split['feature'],\n",
    "            'value': best_split['value'],\n",
    "            'left': left_tree,\n",
    "            'right': right_tree\n",
    "        }\n",
    "    \n",
    "    def _find_best_split(self, X, y):\n",
    "        best_split = None\n",
    "        best_mse = float('inf')\n",
    "        num_features = X.shape[1]\n",
    "\n",
    "        for feature in range(num_features):\n",
    "            unique_values = np.unique(X[:, feature])\n",
    "            split_points = np.percentile(unique_values, [25, 50, 75]) if len(unique_values) > 10 else unique_values\n",
    "            \n",
    "            for value in split_points:\n",
    "                left_indices = X[:, feature] <= value\n",
    "                right_indices = ~left_indices\n",
    "                \n",
    "                if np.sum(left_indices) < 2 or np.sum(right_indices) < 2:\n",
    "                    continue\n",
    "                \n",
    "                left_y = y[left_indices]\n",
    "                right_y = y[right_indices]\n",
    "                \n",
    "                mse = (np.var(left_y) * len(left_y) + np.var(right_y) * len(right_y)) / len(y)\n",
    "                \n",
    "                if mse < best_mse:\n",
    "                    best_split = {'feature': feature, 'value': value}\n",
    "                    best_mse = mse\n",
    "        \n",
    "        return best_split\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if issparse(X):\n",
    "            X = X.toarray()\n",
    "            \n",
    "        return np.array([self._predict(sample, self.tree_) for sample in X])\n",
    "    \n",
    "    def _predict(self, sample, tree):\n",
    "        if not isinstance(tree, dict):\n",
    "            return tree\n",
    "        \n",
    "        if sample[tree['feature']] <= tree['value']:\n",
    "            return self._predict(sample, tree['left'])\n",
    "        return self._predict(sample, tree['right'])\n",
    "\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, max_features='sqrt'):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.trees = []\n",
    "        self.feature_indices = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, (pd.Series, pd.DataFrame)):\n",
    "            y = y.values\n",
    "            \n",
    "        n_features = X.shape[1]\n",
    "        max_feats = int(np.sqrt(n_features)) if self.max_features == 'sqrt' else self.max_features\n",
    "        \n",
    "        for _ in range(self.n_estimators):\n",
    "            X_sample, y_sample = resample(X, y)\n",
    "            feature_idx = np.random.choice(n_features, max_feats, replace=False)\n",
    "            X_sub = X_sample[:, feature_idx]\n",
    "            \n",
    "            tree = DecisionTree(max_depth=self.max_depth)\n",
    "            tree.fit(X_sub, y_sample)\n",
    "            \n",
    "            self.trees.append(tree)\n",
    "            self.feature_indices.append(feature_idx)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if issparse(X):\n",
    "            X = X.toarray()\n",
    "            \n",
    "        all_preds = np.zeros((self.n_estimators, X.shape[0]))\n",
    "        \n",
    "        for i, (tree, feat_idx) in enumerate(zip(self.trees, self.feature_indices)):\n",
    "            X_sub = X[:, feat_idx]\n",
    "            all_preds[i] = tree.predict(X_sub)\n",
    "            \n",
    "        return np.mean(all_preds, axis=0)\n",
    "\n",
    "\n",
    "class CustomKNN:\n",
    "    def __init__(self, k=5, metric='cosine'):\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        \n",
    "    def _cosine_similarity(self, a, b):\n",
    "        norm_a = np.linalg.norm(a)\n",
    "        norm_b = np.linalg.norm(b)\n",
    "        return np.dot(a, b) / (norm_a * norm_b) if norm_a > 0 and norm_b > 0 else 0\n",
    "    \n",
    "    def _euclidean_distance(self, a, b):\n",
    "        return np.sqrt(np.sum((a - b) ** 2))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if issparse(X):\n",
    "            X = X.toarray()\n",
    "        self.X_train = X\n",
    "        self.y_train = y.values if isinstance(y, pd.Series) else y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if issparse(X):\n",
    "            X = X.toarray()\n",
    "            \n",
    "        predictions = []\n",
    "        for sample in X:\n",
    "            distances = []\n",
    "            if self.metric == 'cosine':\n",
    "                distances = [self._cosine_similarity(sample, x) for x in self.X_train]\n",
    "                neighbors = np.argpartition(distances, -self.k)[-self.k:]\n",
    "            else:\n",
    "                distances = [self._euclidean_distance(sample, x) for x in self.X_train]\n",
    "                neighbors = np.argpartition(distances, self.k)[:self.k]\n",
    "            \n",
    "            prediction = np.mean(self.y_train[neighbors])\n",
    "            predictions.append(prediction)\n",
    "            \n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "# ====================== DATA PIPELINE ======================\n",
    "\n",
    "print(\"Loading and preprocessing data...\")\n",
    "df = pd.read_csv('laptop_data.csv')\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "# Data cleaning\n",
    "df[\"Price\"] = df[\"Price\"].astype(float)\n",
    "df[\"Ram\"] = df[\"Ram\"].str.replace(\"GB\", \"\").astype(\"int\")\n",
    "df[\"Weight\"] = df[\"Weight\"].str.replace(\"kg\", \"\").astype(\"float\")\n",
    "\n",
    "# Feature engineering\n",
    "df[\"Touchscreen\"] = df[\"ScreenResolution\"].apply(lambda x: 1 if \"Touchscreen\" in x else 0)\n",
    "df[\"Ips\"] = df[\"ScreenResolution\"].apply(lambda x: 1 if \"IPS\" in x else 0)\n",
    "\n",
    "# Process resolution\n",
    "temp = df[\"ScreenResolution\"].str.split(\"x\", n=1, expand=True)\n",
    "df[\"X_res\"] = temp[0].str.replace(',', '').str.findall(r'(\\d+\\.?\\d+)').apply(lambda x: x[0] if x else 0).astype(int)\n",
    "df[\"Y_res\"] = temp[1].astype(int)\n",
    "df['ppi'] = (((df['X_res']**2) + (df['Y_res']**2))**0.5/df['Inches']).astype('float')\n",
    "df.drop(columns=[\"ScreenResolution\", \"X_res\", \"Y_res\", \"Inches\"], inplace=True)\n",
    "\n",
    "# Process CPU\n",
    "df['Cpu Name'] = df['Cpu'].apply(lambda x: \" \".join(x.split()[0:3]))\n",
    "def fetch_processor(text):\n",
    "    if text in ['Intel Core i7', 'Intel Core i5', 'Intel Core i3']:\n",
    "        return text\n",
    "    elif text.split()[0] == 'Intel':\n",
    "        return 'Other Intel Processor'\n",
    "    else:\n",
    "        return 'AMD Processor'\n",
    "df['Cpu brand'] = df['Cpu Name'].apply(fetch_processor)\n",
    "df.drop(columns=['Cpu', 'Cpu Name'], inplace=True)\n",
    "\n",
    "# Process Memory\n",
    "df['Memory'] = df['Memory'].astype(str).replace(r'\\.0', '', regex=True)\n",
    "df[\"Memory\"] = df[\"Memory\"].str.replace('GB', '').str.replace('TB', '000')\n",
    "new = df[\"Memory\"].str.split(\"+\", n=1, expand=True)\n",
    "df[\"first\"] = new[0].str.strip().str.replace(r'\\D', '', regex=True).astype(int)\n",
    "df[\"second\"] = new[1].fillna(\"0\").str.replace(r'\\D', '', regex=True).astype(int)\n",
    "df[\"HDD\"] = (df[\"first\"] * df[\"first\"].apply(lambda x: 1 if \"HDD\" in str(x) else 0)) + \\\n",
    "            (df[\"second\"] * df[\"second\"].apply(lambda x: 1 if \"HDD\" in str(x) else 0))\n",
    "df[\"SSD\"] = (df[\"first\"] * df[\"first\"].apply(lambda x: 1 if \"SSD\" in str(x) else 0)) + \\\n",
    "            (df[\"second\"] * df[\"second\"].apply(lambda x: 1 if \"SSD\" in str(x) else 0))\n",
    "df.drop(columns=['first', 'second', 'Memory'], inplace=True)\n",
    "\n",
    "# Process GPU\n",
    "df['Gpu brand'] = df['Gpu'].apply(lambda x: x.split()[0])\n",
    "df = df[df['Gpu brand'] != 'ARM']\n",
    "df.drop(columns=['Gpu'], inplace=True)\n",
    "\n",
    "# Process OS\n",
    "def cat_os(inp):\n",
    "    if inp in ['Windows 10', 'Windows 7', 'Windows 10 S', 'Windows 11']:\n",
    "        return 'Windows'\n",
    "    elif inp in ['macOS', 'Mac OS X']:\n",
    "        return 'Mac'\n",
    "    else:\n",
    "        return 'Others/No OS/Linux'\n",
    "df['os'] = df['OpSys'].apply(cat_os)\n",
    "df.drop(columns=['OpSys'], inplace=True)\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=['Price'])\n",
    "y = np.log(df['Price'])  # Log transformation for better modeling\n",
    "\n",
    "# Preprocessing pipeline\n",
    "cat_cols = ['Company', 'TypeName', 'Cpu brand', 'Gpu brand', 'os']\n",
    "num_cols = ['Ram', 'Weight', 'Touchscreen', 'Ips', 'ppi', 'HDD', 'SSD']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "])\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Transform\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "if issparse(X_train_transformed):\n",
    "    X_train_transformed = X_train_transformed.toarray()\n",
    "if issparse(X_test_transformed):\n",
    "    X_test_transformed = X_test_transformed.toarray()\n",
    "\n",
    "# ====================== MODEL TRAINING ======================\n",
    "\n",
    "print(\"\\nTraining custom Random Forest...\")\n",
    "rf_model = RandomForest(n_estimators=100, max_depth=10, max_features='sqrt')\n",
    "rf_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "y_pred_rf = rf_model.predict(X_test_transformed)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"\\nRandom Forest Performance:\")\n",
    "print(f\"MSE: {mse_rf:.4f}\")\n",
    "print(f\"MAE: {mae_rf:.4f}\")\n",
    "print(f\"R² Score: {r2_rf:.4f}\")\n",
    "\n",
    "print(\"\\nTraining custom KNN...\")\n",
    "knn_model = CustomKNN(k=5, metric='cosine')\n",
    "knn_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Evaluate KNN\n",
    "y_pred_knn = knn_model.predict(X_test_transformed)\n",
    "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
    "mae_knn = mean_absolute_error(y_test, y_pred_knn)\n",
    "r2_knn = r2_score(y_test, y_pred_knn)\n",
    "\n",
    "print(\"\\nKNN Performance:\")\n",
    "print(f\"MSE: {mse_knn:.4f}\")\n",
    "print(f\"MAE: {mae_knn:.4f}\")\n",
    "print(f\"R² Score: {r2_knn:.4f}\")\n",
    "\n",
    "# ====================== SAVE MODELS ======================\n",
    "\n",
    "print(\"\\nSaving models...\")\n",
    "joblib.dump({\n",
    "    'df': df,\n",
    "    'preprocessor': preprocessor,\n",
    "    'random_forest': rf_model,\n",
    "    'knn': knn_model\n",
    "}, 'laptop_models.pkl')\n",
    "\n",
    "print(\"Saved successfully to laptop_models.pkl ✅\")\n",
    "\n",
    "# ====================== GENERIC RECOMMENDATION SYSTEM ======================\n",
    "\n",
    "class LaptopRecommender:\n",
    "    def __init__(self, models_path='laptop_models.pkl'):\n",
    "        # Load saved models and data\n",
    "        saved_data = joblib.load(models_path)\n",
    "        self.df = saved_data['df']\n",
    "        self.preprocessor = saved_data['preprocessor']\n",
    "        self.rf_model = saved_data['random_forest']\n",
    "        \n",
    "        # Preprocess the entire dataset\n",
    "        self.X_all = self.preprocessor.transform(self.df.drop(columns=['Price']))\n",
    "        if issparse(self.X_all):\n",
    "            self.X_all = self.X_all.toarray()\n",
    "            \n",
    "        # Get predicted prices\n",
    "        self.all_pred_prices = np.exp(self.rf_model.predict(self.X_all))\n",
    "        self.df['PredictedPrice'] = self.all_pred_prices\n",
    "        \n",
    "        # Default feature weights\n",
    "        self.feature_weights = {\n",
    "            'Ram': 0.3,\n",
    "            'SSD': 0.3,\n",
    "            'ppi': 0.2,\n",
    "            'Weight': 0.1,\n",
    "            'Company': 0.05,\n",
    "            'Cpu brand': 0.05\n",
    "        }\n",
    "        \n",
    "        # Normalize features for scoring\n",
    "        self._normalize_features()\n",
    "        \n",
    "    def _normalize_features(self):\n",
    "        \"\"\"Normalize features to 0-1 scale for scoring with NaN handling\"\"\"\n",
    "        # Handle numerical features with checks for NaN or division by zero\n",
    "        for col in ['Ram', 'SSD', 'ppi', 'Weight']:\n",
    "            col_min = self.df[col].min()\n",
    "            col_max = self.df[col].max()\n",
    "            if col_max == col_min:\n",
    "                self.df[f'{col}_norm'] = 0.5  # Assign neutral score if no variation\n",
    "            else:\n",
    "                self.df[f'{col}_norm'] = (self.df[col] - col_min) / (col_max - col_min)\n",
    "                self.df[f'{col}_norm'] = self.df[f'{col}_norm'].fillna(0.5)  # Handle NaN\n",
    "        # Invert Weight (lower is better)\n",
    "        self.df['Weight_norm'] = 1 - self.df['Weight_norm']\n",
    "        \n",
    "        # Neutral brand and CPU scores (no regional bias)\n",
    "        self.df['Company_norm'] = 1.0\n",
    "        self.df['Cpu_brand_norm'] = 1.0\n",
    "\n",
    "    def calculate_score(self, custom_weights=None, brand_boost=None, cpu_boost=None):\n",
    "        \"\"\"\n",
    "        Calculate scores for laptops\n",
    "        \n",
    "        Parameters:\n",
    "        - custom_weights: Override default weight distribution\n",
    "        - brand_boost: Dict of brand multipliers (e.g., {'Dell': 1.2})\n",
    "        - cpu_boost: Dict of CPU multipliers (e.g., {'Intel Core i7': 1.3})\n",
    "        \"\"\"\n",
    "        weights = custom_weights if custom_weights else self.feature_weights\n",
    "        \n",
    "        # Apply brand boosts if provided\n",
    "        if brand_boost:\n",
    "            self.df['Company_norm'] = self.df['Company'].map(brand_boost).fillna(1.0)\n",
    "        \n",
    "        # Apply CPU boosts if provided\n",
    "        if cpu_boost:\n",
    "            self.df['Cpu_brand_norm'] = self.df['Cpu brand'].map(cpu_boost).fillna(1.0)\n",
    "        \n",
    "        # Calculate weighted score\n",
    "        score = (\n",
    "            self.df['Ram_norm'] * weights.get('Ram', 0) +\n",
    "            self.df['SSD_norm'] * weights.get('SSD', 0) +\n",
    "            self.df['ppi_norm'] * weights.get('ppi', 0) +\n",
    "            self.df['Weight_norm'] * weights.get('Weight', 0) +\n",
    "            self.df['Company_norm'] * weights.get('Company', 0) +\n",
    "            self.df['Cpu_brand_norm'] * weights.get('Cpu brand', 0)\n",
    "        )\n",
    "        \n",
    "        return score\n",
    "\n",
    "    def recommend(self, budget, weights=None, brand_prefs=None, cpu_prefs=None, \n",
    "                 top_n=5, price_importance=0.3, min_ram=None, min_ssd=None):\n",
    "        \"\"\"\n",
    "        Recommend laptops based on budget and preferences\n",
    "        \n",
    "        Parameters:\n",
    "        - budget: Maximum budget\n",
    "        - weights: Custom feature weights\n",
    "        - brand_prefs: Brand preferences\n",
    "        - cpu_prefs: CPU preferences\n",
    "        - top_n: Number of recommendations\n",
    "        - price_importance: How much to prioritize price (0-1)\n",
    "        - min_ram: Minimum RAM requirement\n",
    "        - min_ssd: Minimum SSD requirement\n",
    "        \"\"\"\n",
    "        # Filter by budget and requirements\n",
    "        mask = self.df['PredictedPrice'] <= budget\n",
    "        if min_ram:\n",
    "            mask &= self.df['Ram'] >= min_ram\n",
    "        if min_ssd:\n",
    "            mask &= self.df['SSD'] >= min_ssd\n",
    "            \n",
    "        budget_df = self.df[mask].copy()\n",
    "        \n",
    "        if len(budget_df) == 0:\n",
    "            closest = self.df.iloc[(self.df['PredictedPrice'] - budget).abs().argsort()[:5]]\n",
    "            print(f\"⚠️ No laptops within budget {budget:,.2f}. Showing closest options:\")\n",
    "            return closest[['Company', 'TypeName', 'Ram', 'SSD', 'Weight', 'PredictedPrice']]\n",
    "        \n",
    "        # Calculate scores\n",
    "        budget_df['FeatureScore'] = self.calculate_score(weights, brand_prefs, cpu_prefs)\n",
    "        \n",
    "        # Price score (higher is better - cheaper laptops score higher)\n",
    "        price_range = budget_df['PredictedPrice'].max() - budget_df['PredictedPrice'].min()\n",
    "        budget_df['PriceScore'] = 1 - ((budget_df['PredictedPrice'] - budget_df['PredictedPrice'].min()) / \n",
    "                                      (price_range if price_range != 0 else 1))\n",
    "        budget_df['PriceScore'] = budget_df['PriceScore'].fillna(0.5)  # Handle NaN\n",
    "        \n",
    "        # Combined score\n",
    "        budget_df['CombinedScore'] = (\n",
    "            (1 - price_importance) * budget_df['FeatureScore'] +\n",
    "            price_importance * budget_df['PriceScore']\n",
    "        )\n",
    "        \n",
    "        # Format prices\n",
    "        budget_df['Price'] = budget_df['PredictedPrice'].apply(lambda x: f\"{x:,.2f}\")\n",
    "        \n",
    "        # Sort and return recommendations\n",
    "        recommendations = budget_df.sort_values(['CombinedScore', 'PredictedPrice'], \n",
    "                                              ascending=[False, True])\n",
    "        \n",
    "        return recommendations.head(top_n)[[\n",
    "            'Company', 'TypeName', 'Ram', 'SSD', 'Weight', 'Price',\n",
    "            'FeatureScore', 'PriceScore', 'CombinedScore'\n",
    "        ]]\n",
    "\n",
    "# ====================== EXAMPLE USAGE ======================\n",
    "\n",
    "print(\"\\nTesting generic recommendation system...\")\n",
    "recommender = LaptopRecommender()\n",
    "\n",
    "# Example 1: Student laptop under 50000\n",
    "print(\"\\nStudent laptop recommendations under 50000:\")\n",
    "student_weights = {\n",
    "    'Ram': 0.3,\n",
    "    'SSD': 0.3,\n",
    "    'Weight': 0.2,\n",
    "    'Company': 0.2\n",
    "}\n",
    "print(recommender.recommend(\n",
    "    budget=50000,\n",
    "    weights=student_weights,\n",
    "    min_ram=8,\n",
    "    price_importance=0.5\n",
    "))\n",
    "\n",
    "# Example 2: Premium laptop under 100000\n",
    "print(\"\\nPremium laptop recommendations under 100000:\")\n",
    "premium_brands = {\n",
    "    'Apple': 1.5,\n",
    "    'Dell': 1.3,\n",
    "    'HP': 1.2\n",
    "}\n",
    "print(recommender.recommend(\n",
    "    budget=100000,\n",
    "    brand_prefs=premium_brands,\n",
    "    min_ram=16,\n",
    "    min_ssd=512,\n",
    "    price_importance=0.2\n",
    "))\n",
    "\n",
    "# Example 3: Budget gaming laptop under 70000\n",
    "print(\"\\nBudget gaming laptop under 70000:\")\n",
    "gaming_weights = {\n",
    "    'Ram': 0.4,\n",
    "    'SSD': 0.3,\n",
    "    'Cpu brand': 0.3\n",
    "}\n",
    "gaming_cpus = {\n",
    "    'Intel Core i7': 1.5,\n",
    "    'Intel Core i5': 1.2,\n",
    "    'AMD Processor': 1.1\n",
    "}\n",
    "print(recommender.recommend(\n",
    "    budget=70000,\n",
    "    weights=gaming_weights,\n",
    "    cpu_prefs=gaming_cpus,\n",
    "    min_ram=8,\n",
    "    min_ssd=256\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fbf77b0-685a-45e5-a12f-42539d21f513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "\n",
      "Training custom Random Forest...\n",
      "\n",
      "Random Forest Performance:\n",
      "MSE: 0.1765\n",
      "MAE: 0.3382\n",
      "R² Score: 0.5420\n",
      "\n",
      "Training custom KNN...\n",
      "\n",
      "KNN Performance:\n",
      "MSE: 0.0704\n",
      "MAE: 0.1964\n",
      "R² Score: 0.8174\n",
      "\n",
      "Training custom K-Means...\n",
      "\n",
      "K-Means Performance:\n",
      "Silhouette Score: 0.1586\n",
      "\n",
      "Saving models...\n",
      "Saved successfully to laptop_models_full_custom.pkl ✅\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heapq\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.utils import resample\n",
    "from scipy.sparse import issparse\n",
    "import joblib\n",
    "\n",
    "# ====================== CUSTOM MODELS ======================\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, (pd.Series, pd.DataFrame)):\n",
    "            y = y.values\n",
    "            \n",
    "        self.tree_ = self._build_tree(X, y, depth=0)\n",
    "    \n",
    "    def _build_tree(self, X, y, depth):\n",
    "        num_samples = X.shape[0]\n",
    "        \n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or \\\n",
    "           num_samples < self.min_samples_split or \\\n",
    "           len(np.unique(y)) == 1:\n",
    "            return np.mean(y)\n",
    "\n",
    "        best_split = self._find_best_split(X, y)\n",
    "        if best_split is None:\n",
    "            return np.mean(y)\n",
    "        \n",
    "        left_indices = X[:, best_split['feature']] <= best_split['value']\n",
    "        right_indices = ~left_indices\n",
    "        \n",
    "        if np.sum(left_indices) == 0 or np.sum(right_indices) == 0:\n",
    "            return np.mean(y)\n",
    "        \n",
    "        left_tree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_tree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "        \n",
    "        return {\n",
    "            'feature': best_split['feature'],\n",
    "            'value': best_split['value'],\n",
    "            'left': left_tree,\n",
    "            'right': right_tree\n",
    "        }\n",
    "    \n",
    "    def _find_best_split(self, X, y):\n",
    "        best_split = None\n",
    "        best_mse = float('inf')\n",
    "        num_features = X.shape[1]\n",
    "\n",
    "        for feature in range(num_features):\n",
    "            unique_values = np.unique(X[:, feature])\n",
    "            split_points = np.percentile(unique_values, [25, 50, 75]) if len(unique_values) > 10 else unique_values\n",
    "            \n",
    "            for value in split_points:\n",
    "                left_indices = X[:, feature] <= value\n",
    "                right_indices = ~left_indices\n",
    "                \n",
    "                if np.sum(left_indices) < 2 or np.sum(right_indices) < 2:\n",
    "                    continue\n",
    "                \n",
    "                left_y = y[left_indices]\n",
    "                right_y = y[right_indices]\n",
    "                \n",
    "                mse = (np.var(left_y) * len(left_y) + np.var(right_y) * len(right_y)) / len(y)\n",
    "                \n",
    "                if mse < best_mse:\n",
    "                    best_split = {'feature': feature, 'value': value}\n",
    "                    best_mse = mse\n",
    "        \n",
    "        return best_split\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if issparse(X):\n",
    "            X = X.toarray()\n",
    "            \n",
    "        return np.array([self._predict(sample, self.tree_) for sample in X])\n",
    "    \n",
    "    def _predict(self, sample, tree):\n",
    "        if not isinstance(tree, dict):\n",
    "            return tree\n",
    "        \n",
    "        if sample[tree['feature']] <= tree['value']:\n",
    "            return self._predict(sample, tree['left'])\n",
    "        return self._predict(sample, tree['right'])\n",
    "\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, max_features='sqrt'):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.trees = []\n",
    "        self.feature_indices = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, (pd.Series, pd.DataFrame)):\n",
    "            y = y.values\n",
    "            \n",
    "        n_features = X.shape[1]\n",
    "        max_feats = int(np.sqrt(n_features)) if self.max_features == 'sqrt' else self.max_features\n",
    "        \n",
    "        for _ in range(self.n_estimators):\n",
    "            X_sample, y_sample = resample(X, y)\n",
    "            feature_idx = np.random.choice(n_features, max_feats, replace=False)\n",
    "            X_sub = X_sample[:, feature_idx]\n",
    "            \n",
    "            tree = DecisionTree(max_depth=self.max_depth)\n",
    "            tree.fit(X_sub, y_sample)\n",
    "            \n",
    "            self.trees.append(tree)\n",
    "            self.feature_indices.append(feature_idx)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if issparse(X):\n",
    "            X = X.toarray()\n",
    "            \n",
    "        all_preds = np.zeros((self.n_estimators, X.shape[0]))\n",
    "        \n",
    "        for i, (tree, feat_idx) in enumerate(zip(self.trees, self.feature_indices)):\n",
    "            X_sub = X[:, feat_idx]\n",
    "            all_preds[i] = tree.predict(X_sub)\n",
    "            \n",
    "        return np.mean(all_preds, axis=0)\n",
    "\n",
    "\n",
    "class CustomKNN:\n",
    "    def __init__(self, k=5, metric='cosine'):\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        \n",
    "    def _cosine_similarity(self, a, b):\n",
    "        norm_a = np.linalg.norm(a)\n",
    "        norm_b = np.linalg.norm(b)\n",
    "        if norm_a == 0 or norm_b == 0:\n",
    "            return 0\n",
    "        return np.dot(a, b) / (norm_a * norm_b)\n",
    "    \n",
    "    def _euclidean_distance(self, a, b):\n",
    "        return np.sqrt(np.sum((a - b) ** 2))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if issparse(X):\n",
    "            X = X.toarray()\n",
    "        self.X_train = X\n",
    "        self.y_train = y.values if isinstance(y, pd.Series) else y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if issparse(X):\n",
    "            X = X.toarray()\n",
    "            \n",
    "        predictions = []\n",
    "        for sample in X:\n",
    "            distances = []\n",
    "            if self.metric == 'cosine':\n",
    "                distances = [self._cosine_similarity(sample, x) for x in self.X_train]\n",
    "                neighbors = np.argpartition(distances, -self.k)[-self.k:]\n",
    "            else:\n",
    "                distances = [self._euclidean_distance(sample, x) for x in self.X_train]\n",
    "                neighbors = np.argpartition(distances, self.k)[:self.k]\n",
    "            \n",
    "            prediction = np.mean(self.y_train[neighbors])\n",
    "            predictions.append(prediction)\n",
    "            \n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def get_similar_laptops(self, X_input, df, top_n=5):\n",
    "        \"\"\"Get similar laptops with better descriptions\"\"\"\n",
    "        if isinstance(X_input, pd.DataFrame):\n",
    "            X_input = X_input.values\n",
    "        if issparse(X_input):\n",
    "            X_input = X_input.toarray()\n",
    "            \n",
    "        similarities = []\n",
    "        for i, sample in enumerate(self.X_train):\n",
    "            sim = self._cosine_similarity(X_input[0], sample)\n",
    "            similarities.append((sim, i))\n",
    "        \n",
    "        similarities.sort(reverse=True)\n",
    "        top_indices = [idx for _, idx in similarities[:top_n]]\n",
    "        \n",
    "        recommendations = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            laptop = df.iloc[idx].copy()\n",
    "            \n",
    "            company = laptop.get('Company', 'Unknown')\n",
    "            type_name = laptop.get('TypeName', 'Laptop')\n",
    "            ram = laptop.get('Ram', 0)\n",
    "            ssd = laptop.get('SSD', 0)\n",
    "            hdd = laptop.get('HDD', 0)\n",
    "            cpu = laptop.get('Cpu brand', 'Unknown')\n",
    "            gpu = laptop.get('Gpu brand', 'Unknown')\n",
    "            weight = laptop.get('Weight', 0)\n",
    "            price = laptop.get('Price', 0)\n",
    "            \n",
    "            storage_parts = []\n",
    "            if ssd > 0:\n",
    "                storage_parts.append(f\"{ssd}GB SSD\")\n",
    "            if hdd > 0:\n",
    "                storage_parts.append(f\"{hdd}GB HDD\")\n",
    "            storage = \" + \".join(storage_parts) if storage_parts else \"Storage info unavailable\"\n",
    "            \n",
    "            laptop_info = {\n",
    "                'Company': company,\n",
    "                'TypeName': type_name,\n",
    "                'Title': f\"{company} {type_name}\",\n",
    "                'Ram': f\"{ram}GB\",\n",
    "                'Storage': storage,\n",
    "                'Cpu_brand': cpu,\n",
    "                'Gpu_brand': gpu,\n",
    "                'Weight': f\"{weight:.1f}kg\" if weight > 0 else \"Weight N/A\",\n",
    "                'Price': price,\n",
    "                'Similarity': f\"{similarities[i][0]:.2f}\",\n",
    "                'Features': []\n",
    "            }\n",
    "            \n",
    "            if laptop.get('Touchscreen', 0):\n",
    "                laptop_info['Features'].append('Touchscreen')\n",
    "            if laptop.get('Ips', 0):\n",
    "                laptop_info['Features'].append('IPS Display')\n",
    "            \n",
    "            laptop_info['Features'] = ', '.join(laptop_info['Features']) if laptop_info['Features'] else 'Standard Features'\n",
    "            \n",
    "            recommendations.append(laptop_info)\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "\n",
    "class CustomKMeans:\n",
    "    def __init__(self, n_clusters=5, max_iters=100, random_state=None):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iters = max_iters\n",
    "        self.random_state = random_state\n",
    "        self.centroids = None\n",
    "        self.labels_ = None\n",
    "        # Define meaningful cluster names\n",
    "        self.cluster_names = {\n",
    "            0: \"Budget-Friendly Laptops\",\n",
    "            1: \"Mid-Range Performance\",\n",
    "            2: \"Premium Workstations\",\n",
    "            3: \"Gaming & High-Performance\",\n",
    "            4: \"Ultraportable & Business\"\n",
    "        }\n",
    "        \n",
    "    def fit(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if issparse(X):\n",
    "            X = X.toarray()\n",
    "            \n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "            \n",
    "        n_samples, n_features = X.shape\n",
    "        idx = np.random.choice(n_samples, self.n_clusters, replace=False)\n",
    "        self.centroids = X[idx]\n",
    "        \n",
    "        for _ in range(self.max_iters):\n",
    "            old_labels = self.labels_ if self.labels_ is not None else np.zeros(n_samples)\n",
    "            self.labels_ = self._assign_clusters(X)\n",
    "            \n",
    "            if np.all(old_labels == self.labels_):\n",
    "                break\n",
    "                \n",
    "            for k in range(self.n_clusters):\n",
    "                if np.sum(self.labels_ == k) > 0:\n",
    "                    self.centroids[k] = np.mean(X[self.labels_ == k], axis=0)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _assign_clusters(self, X):\n",
    "        distances = np.zeros((X.shape[0], self.n_clusters))\n",
    "        for k in range(self.n_clusters):\n",
    "            distances[:, k] = np.sqrt(np.sum((X - self.centroids[k]) ** 2, axis=1))\n",
    "        return np.argmin(distances, axis=1)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if issparse(X):\n",
    "            X = X.toarray()\n",
    "        return self._assign_clusters(X)\n",
    "    \n",
    "    def get_cluster_examples(self, cluster_id, df, X_all, top_n=5):\n",
    "        \"\"\"Get diverse and representative examples from the cluster\"\"\"\n",
    "        try:\n",
    "            cluster_labels = self.predict(X_all)\n",
    "            cluster_mask = cluster_labels == cluster_id\n",
    "            cluster_df = df[cluster_mask].copy()\n",
    "            \n",
    "            if len(cluster_df) == 0:\n",
    "                return []\n",
    "            \n",
    "            cluster_df['diversity_score'] = (\n",
    "                cluster_df['Ram'] * 0.3 +\n",
    "                cluster_df['SSD'] * 0.0002 +\n",
    "                cluster_df['ppi'] * 0.01 +\n",
    "                (cluster_df['Weight'] * -2) +\n",
    "                cluster_df['Touchscreen'] * 10 +\n",
    "                cluster_df['Ips'] * 10\n",
    "            )\n",
    "            \n",
    "            cluster_df_sorted = cluster_df.sort_values(['diversity_score', 'Price'], \n",
    "                                                      ascending=[False, True])\n",
    "            \n",
    "            examples = []\n",
    "            for _, laptop in cluster_df_sorted.head(top_n).iterrows():\n",
    "                company = laptop.get('Company', 'Unknown')\n",
    "                type_name = laptop.get('TypeName', 'Laptop')\n",
    "                ram = laptop.get('Ram', 0)\n",
    "                ssd = laptop.get('SSD', 0)\n",
    "                hdd = laptop.get('HDD', 0)\n",
    "                cpu = laptop.get('Cpu brand', 'Unknown')\n",
    "                gpu = laptop.get('Gpu brand', 'Unknown')\n",
    "                weight = laptop.get('Weight', 0)\n",
    "                price = laptop.get('Price', 0)\n",
    "                \n",
    "                storage_parts = []\n",
    "                if ssd > 0:\n",
    "                    storage_parts.append(f\"{ssd}GB SSD\")\n",
    "                if hdd > 0:\n",
    "                    storage_parts.append(f\"{hdd}GB HDD\")\n",
    "                storage = \" + \".join(storage_parts) if storage_parts else \"No storage info\"\n",
    "                \n",
    "                features = []\n",
    "                if laptop.get('Touchscreen', 0):\n",
    "                    features.append('Touchscreen')\n",
    "                if laptop.get('Ips', 0):\n",
    "                    features.append('IPS Display')\n",
    "                features_text = ', '.join(features) if features else 'Standard Features'\n",
    "                \n",
    "                example = {\n",
    "                    'Company': company,\n",
    "                    'TypeName': type_name,\n",
    "                    'Title': f\"{company} {type_name}\",\n",
    "                    'Ram': f\"{ram}GB\",\n",
    "                    'Storage': storage,\n",
    "                    'Cpu_brand': cpu,\n",
    "                    'Gpu_brand': gpu,\n",
    "                    'Weight': f\"{weight:.1f}kg\" if weight > 0 else \"Weight N/A\",\n",
    "                    'Price': f\"RS {price:,.2f}\",\n",
    "                    'Features': features_text,\n",
    "                    'Touchscreen': 'Yes' if laptop.get('Touchscreen', 0) else 'No',\n",
    "                    'Ips': 'Yes' if laptop.get('Ips', 0) else 'No',\n",
    "                    'os': laptop.get('os', 'Unknown OS')\n",
    "                }\n",
    "                \n",
    "                examples.append(example)\n",
    "            \n",
    "            return examples\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error getting cluster examples: {e}\")\n",
    "            return []\n",
    "\n",
    "# ====================== DATA PIPELINE ======================\n",
    "\n",
    "print(\"Loading and preprocessing data...\")\n",
    "df = pd.read_csv('laptop_data.csv')\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "# Data cleaning\n",
    "df[\"Ram\"] = df[\"Ram\"].str.replace(\"GB\", \"\").astype(\"int\")\n",
    "df[\"Weight\"] = df[\"Weight\"].str.replace(\"kg\", \"\").astype(\"float\")\n",
    "\n",
    "# Feature engineering\n",
    "df[\"Touchscreen\"] = df[\"ScreenResolution\"].apply(lambda x: 1 if \"Touchscreen\" in x else 0)\n",
    "df[\"Ips\"] = df[\"ScreenResolution\"].apply(lambda x: 1 if \"IPS\" in x else 0)\n",
    "\n",
    "# Process resolution\n",
    "temp = df[\"ScreenResolution\"].str.split(\"x\", n=1, expand=True)\n",
    "df[\"X_res\"] = temp[0].str.replace(',', '').str.findall(r'(\\d+\\.?\\d+)').apply(lambda x: x[0]).astype(int)\n",
    "df[\"Y_res\"] = temp[1].astype(int)\n",
    "df['ppi'] = (((df['X_res']**2) + (df['Y_res']**2))**0.5/df['Inches']).astype('float')\n",
    "df.drop(columns=[\"ScreenResolution\", \"X_res\", \"Y_res\", \"Inches\"], inplace=True)\n",
    "\n",
    "# Process CPU\n",
    "df['Cpu Name'] = df['Cpu'].apply(lambda x: \" \".join(x.split()[0:3]))\n",
    "def fetch_processor(text):\n",
    "    if text in ['Intel Core i7', 'Intel Core i5', 'Intel Core i3']:\n",
    "        return text\n",
    "    elif text.split()[0] == 'Intel':\n",
    "        return 'Other Intel Processor'\n",
    "    else:\n",
    "        return 'AMD Processor'\n",
    "df['Cpu brand'] = df['Cpu Name'].apply(fetch_processor)\n",
    "df.drop(columns=['Cpu', 'Cpu Name'], inplace=True)\n",
    "\n",
    "# Process Memory\n",
    "df['Memory'] = df['Memory'].astype(str).replace(r'\\.0', '', regex=True)\n",
    "df[\"Memory\"] = df[\"Memory\"].str.replace('GB', '').str.replace('TB', '000')\n",
    "new = df[\"Memory\"].str.split(\"+\", n=1, expand=True)\n",
    "df[\"first\"] = new[0].str.strip().str.replace(r'\\D', '', regex=True).astype(int)\n",
    "df[\"second\"] = new[1].fillna(\"0\").str.replace(r'\\D', '', regex=True).astype(int)\n",
    "df[\"HDD\"] = (df[\"first\"] * df[\"first\"].apply(lambda x: 1 if \"HDD\" in str(x) else 0)) + \\\n",
    "            (df[\"second\"] * df[\"second\"].apply(lambda x: 1 if \"HDD\" in str(x) else 0))\n",
    "df[\"SSD\"] = (df[\"first\"] * df[\"first\"].apply(lambda x: 1 if \"SSD\" in str(x) else 0)) + \\\n",
    "            (df[\"second\"] * df[\"second\"].apply(lambda x: 1 if \"SSD\" in str(x) else 0))\n",
    "df.drop(columns=['first', 'second', 'Memory'], inplace=True)\n",
    "\n",
    "# Process GPU\n",
    "df['Gpu brand'] = df['Gpu'].apply(lambda x: x.split()[0])\n",
    "df = df[df['Gpu brand'] != 'ARM']\n",
    "df.drop(columns=['Gpu'], inplace=True)\n",
    "\n",
    "# Process OS\n",
    "def cat_os(inp):\n",
    "    if inp in ['Windows 10', 'Windows 7', 'Windows 10 S']:\n",
    "        return 'Windows'\n",
    "    elif inp in ['macOS', 'Mac OS X']:\n",
    "        return 'Mac'\n",
    "    else:\n",
    "        return 'Others/No OS/Linux'\n",
    "df['os'] = df['OpSys'].apply(cat_os)\n",
    "df.drop(columns=['OpSys'], inplace=True)\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=['Price'])\n",
    "y = np.log(df['Price'])\n",
    "\n",
    "# Preprocessing pipeline\n",
    "cat_cols = ['Company', 'TypeName', 'Cpu brand', 'Gpu brand', 'os']\n",
    "num_cols = ['Ram', 'Weight', 'Touchscreen', 'Ips', 'ppi', 'HDD', 'SSD']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "])\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Transform\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "if issparse(X_train_transformed):\n",
    "    X_train_transformed = X_train_transformed.toarray()\n",
    "if issparse(X_test_transformed):\n",
    "    X_test_transformed = X_test_transformed.toarray()\n",
    "\n",
    "# ====================== MODEL TRAINING ======================\n",
    "\n",
    "print(\"\\nTraining custom Random Forest...\")\n",
    "rf_model = RandomForest(n_estimators=100, max_depth=10, max_features='sqrt')\n",
    "rf_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "y_pred_rf = rf_model.predict(X_test_transformed)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"\\nRandom Forest Performance:\")\n",
    "print(f\"MSE: {mse_rf:.4f}\")\n",
    "print(f\"MAE: {mae_rf:.4f}\")\n",
    "print(f\"R² Score: {r2_rf:.4f}\")\n",
    "\n",
    "print(\"\\nTraining custom KNN...\")\n",
    "knn_model = CustomKNN(k=5, metric='cosine')\n",
    "knn_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Evaluate KNN\n",
    "y_pred_knn = knn_model.predict(X_test_transformed)\n",
    "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
    "mae_knn = mean_absolute_error(y_test, y_pred_knn)\n",
    "r2_knn = r2_score(y_test, y_pred_knn)\n",
    "\n",
    "print(\"\\nKNN Performance:\")\n",
    "print(f\"MSE: {mse_knn:.4f}\")\n",
    "print(f\"MAE: {mae_knn:.4f}\")\n",
    "print(f\"R² Score: {r2_knn:.4f}\")\n",
    "\n",
    "print(\"\\nTraining custom K-Means...\")\n",
    "kmeans_model = CustomKMeans(n_clusters=5, max_iters=100, random_state=42)\n",
    "kmeans_model.fit(X_train_transformed)\n",
    "\n",
    "# Evaluate K-Means\n",
    "from sklearn.metrics import silhouette_score\n",
    "silhouette = silhouette_score(X_train_transformed, kmeans_model.labels_)\n",
    "print(\"\\nK-Means Performance:\")\n",
    "print(f\"Silhouette Score: {silhouette:.4f}\")\n",
    "\n",
    "# ====================== SAVE MODELS ======================\n",
    "\n",
    "print(\"\\nSaving models...\")\n",
    "joblib.dump({\n",
    "    'df': df,\n",
    "    'preprocessor': preprocessor,\n",
    "    'random_forest': rf_model,\n",
    "    'knn': knn_model,\n",
    "    'kmeans': kmeans_model\n",
    "}, 'laptop_models_full_custom.pkl')\n",
    "\n",
    "print(\"Saved successfully to laptop_models_full_custom.pkl ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92263e53-3cfe-4840-a91e-c364368e8a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
