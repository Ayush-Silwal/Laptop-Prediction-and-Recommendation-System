{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00c16220-1195-4b5d-946a-c52c88fd7ea4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3354635584.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[21], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    mport numpy as np\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import heapq\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.utils import resample\n",
    "from scipy.sparse import issparse\n",
    "import joblib\n",
    "\n",
    "# ====================== CUSTOM MODELS ======================\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, (pd.Series, pd.DataFrame)):\n",
    "            y = y.values\n",
    "            \n",
    "        self.tree_ = self._build_tree(X, y, depth=0)\n",
    "    \n",
    "    def _build_tree(self, X, y, depth):\n",
    "        num_samples = X.shape[0]\n",
    "        \n",
    "        # Stopping conditions\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or \\\n",
    "           num_samples < self.min_samples_split or \\\n",
    "           len(np.unique(y)) == 1:\n",
    "            return np.mean(y)\n",
    "\n",
    "        best_split = self._find_best_split(X, y)\n",
    "        if best_split is None:\n",
    "            return np.mean(y)\n",
    "        \n",
    "        left_indices = X[:, best_split['feature']] <= best_split['value']\n",
    "        right_indices = ~left_indices\n",
    "        \n",
    "        if np.sum(left_indices) == 0 or np.sum(right_indices) == 0:\n",
    "            return np.mean(y)\n",
    "        \n",
    "        left_tree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_tree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "        \n",
    "        return {\n",
    "            'feature': best_split['feature'],\n",
    "            'value': best_split['value'],\n",
    "            'left': left_tree,\n",
    "            'right': right_tree\n",
    "        }\n",
    "    \n",
    "    def _find_best_split(self, X, y):\n",
    "        best_split = None\n",
    "        best_mse = float('inf')\n",
    "        num_features = X.shape[1]\n",
    "\n",
    "        for feature in range(num_features):\n",
    "            unique_values = np.unique(X[:, feature])\n",
    "            split_points = np.percentile(unique_values, [25, 50, 75]) if len(unique_values) > 10 else unique_values\n",
    "            \n",
    "            for value in split_points:\n",
    "                left_indices = X[:, feature] <= value\n",
    "                right_indices = ~left_indices\n",
    "                \n",
    "                if np.sum(left_indices) < 2 or np.sum(right_indices) < 2:\n",
    "                    continue\n",
    "                \n",
    "                left_y = y[left_indices]\n",
    "                right_y = y[right_indices]\n",
    "                \n",
    "                mse = (np.var(left_y) * len(left_y) + np.var(right_y) * len(right_y)) / len(y)\n",
    "                \n",
    "                if mse < best_mse:\n",
    "                    best_split = {'feature': feature, 'value': value}\n",
    "                    best_mse = mse\n",
    "        \n",
    "        return best_split\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if issparse(X):\n",
    "            X = X.toarray()\n",
    "            \n",
    "        return np.array([self._predict(sample, self.tree_) for sample in X])\n",
    "    \n",
    "    def _predict(self, sample, tree):\n",
    "        if not isinstance(tree, dict):\n",
    "            return tree\n",
    "        \n",
    "        if sample[tree['feature']] <= tree['value']:\n",
    "            return self._predict(sample, tree['left'])\n",
    "        return self._predict(sample, tree['right'])\n",
    "\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, max_features='sqrt'):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.trees = []\n",
    "        self.feature_indices = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, (pd.Series, pd.DataFrame)):\n",
    "            y = y.values\n",
    "            \n",
    "        n_features = X.shape[1]\n",
    "        max_feats = int(np.sqrt(n_features)) if self.max_features == 'sqrt' else self.max_features\n",
    "        \n",
    "        for _ in range(self.n_estimators):\n",
    "            X_sample, y_sample = resample(X, y)\n",
    "            feature_idx = np.random.choice(n_features, max_feats, replace=False)\n",
    "            X_sub = X_sample[:, feature_idx]\n",
    "            \n",
    "            tree = DecisionTree(max_depth=self.max_depth)\n",
    "            tree.fit(X_sub, y_sample)\n",
    "            \n",
    "            self.trees.append(tree)\n",
    "            self.feature_indices.append(feature_idx)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if issparse(X):\n",
    "            X = X.toarray()\n",
    "            \n",
    "        all_preds = np.zeros((self.n_estimators, X.shape[0]))\n",
    "        \n",
    "        for i, (tree, feat_idx) in enumerate(zip(self.trees, self.feature_indices)):\n",
    "            X_sub = X[:, feat_idx]\n",
    "            all_preds[i] = tree.predict(X_sub)\n",
    "            \n",
    "        return np.mean(all_preds, axis=0)\n",
    "\n",
    "\n",
    "class CustomKNN:\n",
    "    def __init__(self, k=5, metric='cosine'):\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        \n",
    "    def _cosine_similarity(self, a, b):\n",
    "        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    \n",
    "    def _euclidean_distance(self, a, b):\n",
    "        return np.sqrt(np.sum((a - b) ** 2))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if issparse(X):\n",
    "            X = X.toarray()\n",
    "        self.X_train = X\n",
    "        # Convert y to numpy array if it's a pandas Series\n",
    "        self.y_train = y.values if isinstance(y, pd.Series) else y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if issparse(X):\n",
    "            X = X.toarray()\n",
    "            \n",
    "        predictions = []\n",
    "        for sample in X:\n",
    "            distances = []\n",
    "            if self.metric == 'cosine':\n",
    "                distances = [self._cosine_similarity(sample, x) for x in self.X_train]\n",
    "                # Get indices of k largest cosine similarities\n",
    "                neighbors = np.argpartition(distances, -self.k)[-self.k:]\n",
    "            else:\n",
    "                distances = [self._euclidean_distance(sample, x) for x in self.X_train]\n",
    "                # Get indices of k smallest distances\n",
    "                neighbors = np.argpartition(distances, self.k)[:self.k]\n",
    "            \n",
    "            # Get the average of the neighbors' values\n",
    "            prediction = np.mean(self.y_train[neighbors])\n",
    "            predictions.append(prediction)\n",
    "            \n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "# ====================== DATA PIPELINE ======================\n",
    "\n",
    "print(\"Loading and preprocessing data...\")\n",
    "df = pd.read_csv('laptop_data.csv')\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "# Data cleaning (assuming prices are already in INR)\n",
    "df[\"Price\"] = df[\"Price\"].astype(float)  # Ensure price is numeric\n",
    "df[\"Ram\"] = df[\"Ram\"].str.replace(\"GB\", \"\").astype(\"int\")\n",
    "df[\"Weight\"] = df[\"Weight\"].str.replace(\"kg\", \"\").astype(\"float\")\n",
    "\n",
    "# Feature engineering with Indian market considerations\n",
    "df[\"Touchscreen\"] = df[\"ScreenResolution\"].apply(lambda x: 1 if \"Touchscreen\" in x else 0)\n",
    "df[\"Ips\"] = df[\"ScreenResolution\"].apply(lambda x: 1 if \"IPS\" in x else 0)\n",
    "\n",
    "# Process resolution\n",
    "temp = df[\"ScreenResolution\"].str.split(\"x\", n=1, expand=True)\n",
    "df[\"X_res\"] = temp[0].str.replace(',', '').str.findall(r'(\\d+\\.?\\d+)').apply(lambda x: x[0]).astype(int)\n",
    "df[\"Y_res\"] = temp[1].astype(int)\n",
    "df['ppi'] = (((df['X_res']**2) + (df['Y_res']**2))**0.5/df['Inches']).astype('float')\n",
    "df.drop(columns=[\"ScreenResolution\", \"X_res\", \"Y_res\", \"Inches\"], inplace=True)\n",
    "\n",
    "# Process CPU - adding Indian market specific processors\n",
    "df['Cpu Name'] = df['Cpu'].apply(lambda x: \" \".join(x.split()[0:3]))\n",
    "def fetch_processor(text):\n",
    "    if text in ['Intel Core i7', 'Intel Core i5', 'Intel Core i3']:\n",
    "        return text\n",
    "    elif text.split()[0] == 'Intel':\n",
    "        return 'Other Intel Processor'\n",
    "    else:\n",
    "        return 'AMD Processor'\n",
    "df['Cpu brand'] = df['Cpu Name'].apply(fetch_processor)\n",
    "df.drop(columns=['Cpu', 'Cpu Name'], inplace=True)\n",
    "\n",
    "# Process Memory (common Indian configurations)\n",
    "df['Memory'] = df['Memory'].astype(str).replace(r'\\.0', '', regex=True)\n",
    "df[\"Memory\"] = df[\"Memory\"].str.replace('GB', '').str.replace('TB', '000')\n",
    "new = df[\"Memory\"].str.split(\"+\", n=1, expand=True)\n",
    "df[\"first\"] = new[0].str.strip().str.replace(r'\\D', '', regex=True).astype(int)\n",
    "df[\"second\"] = new[1].fillna(\"0\").str.replace(r'\\D', '', regex=True).astype(int)\n",
    "df[\"HDD\"] = (df[\"first\"] * df[\"first\"].apply(lambda x: 1 if \"HDD\" in str(x) else 0)) + \\\n",
    "            (df[\"second\"] * df[\"second\"].apply(lambda x: 1 if \"HDD\" in str(x) else 0))\n",
    "df[\"SSD\"] = (df[\"first\"] * df[\"first\"].apply(lambda x: 1 if \"SSD\" in str(x) else 0)) + \\\n",
    "            (df[\"second\"] * df[\"second\"].apply(lambda x: 1 if \"SSD\" in str(x) else 0))\n",
    "df.drop(columns=['first', 'second', 'Memory'], inplace=True)\n",
    "\n",
    "# Process GPU - focusing on brands available in India\n",
    "df['Gpu brand'] = df['Gpu'].apply(lambda x: x.split()[0])\n",
    "df = df[df['Gpu brand'] != 'ARM']\n",
    "df.drop(columns=['Gpu'], inplace=True)\n",
    "\n",
    "# Process OS - adding Indian market specific OS versions\n",
    "def cat_os(inp):\n",
    "    if inp in ['Windows 10', 'Windows 7', 'Windows 10 S', 'Windows 11']:\n",
    "        return 'Windows'\n",
    "    elif inp in ['macOS', 'Mac OS X']:\n",
    "        return 'Mac'\n",
    "    else:\n",
    "        return 'Others/No OS/Linux'\n",
    "df['os'] = df['OpSys'].apply(cat_os)\n",
    "df.drop(columns=['OpSys'], inplace=True)\n",
    "\n",
    "# Features and target (price already in INR)\n",
    "X = df.drop(columns=['Price'])\n",
    "y = np.log(df['Price'])  # Using log transformation for better modeling\n",
    "\n",
    "# Preprocessing pipeline\n",
    "cat_cols = ['Company', 'TypeName', 'Cpu brand', 'Gpu brand', 'os']\n",
    "num_cols = ['Ram', 'Weight', 'Touchscreen', 'Ips', 'ppi', 'HDD', 'SSD']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "])\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Transform\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "if issparse(X_train_transformed):\n",
    "    X_train_transformed = X_train_transformed.toarray()\n",
    "if issparse(X_test_transformed):\n",
    "    X_test_transformed = X_test_transformed.toarray()\n",
    "\n",
    "# ====================== MODEL TRAINING ======================\n",
    "\n",
    "print(\"\\nTraining custom Random Forest...\")\n",
    "rf_model = RandomForest(n_estimators=100, max_depth=10, max_features='sqrt')\n",
    "rf_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "y_pred_rf = rf_model.predict(X_test_transformed)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"\\nRandom Forest Performance:\")\n",
    "print(f\"MSE: {mse_rf:.4f}\")\n",
    "print(f\"MAE: {mae_rf:.4f}\")\n",
    "print(f\"R² Score: {r2_rf:.4f}\")\n",
    "\n",
    "print(\"\\nTraining custom KNN...\")\n",
    "knn_model = CustomKNN(k=5, metric='cosine')\n",
    "knn_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Evaluate KNN\n",
    "y_pred_knn = knn_model.predict(X_test_transformed)\n",
    "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
    "mae_knn = mean_absolute_error(y_test, y_pred_knn)\n",
    "r2_knn = r2_score(y_test, y_pred_knn)\n",
    "\n",
    "print(\"\\nKNN Performance:\")\n",
    "print(f\"MSE: {mse_knn:.4f}\")\n",
    "print(f\"MAE: {mae_knn:.4f}\")\n",
    "print(f\"R² Score: {r2_knn:.4f}\")\n",
    "\n",
    "# ====================== SAVE MODELS ======================\n",
    "\n",
    "print(\"\\nSaving models...\")\n",
    "joblib.dump({\n",
    "    'df': df,\n",
    "    'preprocessor': preprocessor,\n",
    "    'random_forest': rf_model,\n",
    "    'knn': knn_model\n",
    "}, 'laptop_models_inr.pkl')\n",
    "\n",
    "print(\"Saved successfully to laptop_models_inr.pkl ✅\")\n",
    "\n",
    "# ====================== INDIAN MARKET RECOMMENDATION SYSTEM ======================\n",
    "\n",
    "class IndiaLaptopRecommender:\n",
    "    def __init__(self, models_path='laptop_models_inr.pkl'):\n",
    "        # Load saved models and data\n",
    "        saved_data = joblib.load(models_path)\n",
    "        self.df = saved_data['df']\n",
    "        self.preprocessor = saved_data['preprocessor']\n",
    "        self.rf_model = saved_data['random_forest']\n",
    "        \n",
    "        # Preprocess the entire dataset\n",
    "        self.X_all = self.preprocessor.transform(self.df.drop(columns=['Price']))\n",
    "        if issparse(self.X_all):\n",
    "            self.X_all = self.X_all.toarray()\n",
    "            \n",
    "        # Get predicted prices (already in INR)\n",
    "        self.all_pred_prices = np.exp(self.rf_model.predict(self.X_all))\n",
    "        self.df['PredictedPrice'] = self.all_pred_prices\n",
    "        \n",
    "        # Indian market specific feature weights\n",
    "        self.indian_feature_weights = {\n",
    "            'Ram': 0.25,\n",
    "            'SSD': 0.25,\n",
    "            'ppi': 0.15,\n",
    "            'Weight': 0.15,\n",
    "            'Company': 0.1,  # Brand matters more in India\n",
    "            'Cpu brand': 0.1  # CPU brand preference strong in India\n",
    "        }\n",
    "        \n",
    "        # Normalize features for scoring\n",
    "        self._normalize_features()\n",
    "        \n",
    "    def _normalize_features(self):\n",
    "        \"\"\"Normalize features to 0-1 scale for scoring\"\"\"\n",
    "        # Hardware specs\n",
    "        self.df['Ram_norm'] = (self.df['Ram'] - self.df['Ram'].min()) / (self.df['Ram'].max() - self.df['Ram'].min())\n",
    "        self.df['SSD_norm'] = (self.df['SSD'] - self.df['SSD'].min()) / (self.df['SSD'].max() - self.df['SSD'].min())\n",
    "        self.df['ppi_norm'] = (self.df['ppi'] - self.df['ppi'].min()) / (self.df['ppi'].max() - self.df['ppi'].min())\n",
    "        self.df['Weight_norm'] = 1 - ((self.df['Weight'] - self.df['Weight'].min()) / \n",
    "                                      (self.df['Weight'].max() - self.df['Weight'].min()))\n",
    "        \n",
    "        # Brand preferences (Indian market specific)\n",
    "        popular_brands = ['HP', 'Dell', 'Lenovo', 'Asus', 'Acer']\n",
    "        self.df['Company_norm'] = self.df['Company'].apply(lambda x: 1.2 if x in popular_brands else 1)\n",
    "        \n",
    "        # CPU preferences (Indian market specific)\n",
    "        self.df['Cpu_brand_norm'] = self.df['Cpu brand'].apply(\n",
    "            lambda x: 1.3 if 'Intel Core i7' in x else 1.1 if 'Intel Core i5' in x else 1\n",
    "        )\n",
    "\n",
    "    def calculate_score(self, custom_weights=None, brand_boost=None, cpu_boost=None):\n",
    "        \"\"\"\n",
    "        Calculate scores with Indian market considerations\n",
    "        \n",
    "        Parameters:\n",
    "        - custom_weights: Override default weight distribution\n",
    "        - brand_boost: Dict of brand multipliers (e.g., {'Dell': 1.2})\n",
    "        - cpu_boost: Dict of CPU multipliers (e.g., {'Intel Core i7': 1.3})\n",
    "        \"\"\"\n",
    "        weights = custom_weights if custom_weights else self.indian_feature_weights\n",
    "        \n",
    "        # Apply brand boosts if provided\n",
    "        if brand_boost:\n",
    "            self.df['Company_norm'] = self.df['Company'].map(brand_boost).fillna(1)\n",
    "        \n",
    "        # Apply CPU boosts if provided\n",
    "        if cpu_boost:\n",
    "            self.df['Cpu_brand_norm'] = self.df['Cpu brand'].map(cpu_boost).fillna(1)\n",
    "        \n",
    "        # Calculate weighted score\n",
    "        score = (\n",
    "            self.df['Ram_norm'] * weights.get('Ram', 0) +\n",
    "            self.df['SSD_norm'] * weights.get('SSD', 0) +\n",
    "            self.df['ppi_norm'] * weights.get('ppi', 0) +\n",
    "            self.df['Weight_norm'] * weights.get('Weight', 0) +\n",
    "            self.df['Company_norm'] * weights.get('Company', 0) +\n",
    "            self.df['Cpu_brand_norm'] * weights.get('Cpu brand', 0)\n",
    "        )\n",
    "        \n",
    "        return score\n",
    "\n",
    "    def recommend(self, budget_inr, weights=None, brand_prefs=None, cpu_prefs=None, \n",
    "                 top_n=5, price_importance=0.3, min_ram=None, min_ssd=None):\n",
    "        \"\"\"\n",
    "        Recommend laptops for Indian market\n",
    "        \n",
    "        Parameters:\n",
    "        - budget_inr: Budget in INR\n",
    "        - weights: Custom feature weights\n",
    "        - brand_prefs: Brand preferences\n",
    "        - cpu_prefs: CPU preferences\n",
    "        - top_n: Number of recommendations\n",
    "        - price_importance: How much to prioritize price (0-1)\n",
    "        - min_ram: Minimum RAM requirement\n",
    "        - min_ssd: Minimum SSD requirement\n",
    "        \"\"\"\n",
    "        # Filter by budget and requirements\n",
    "        mask = self.df['PredictedPrice'] <= budget_inr\n",
    "        if min_ram:\n",
    "            mask &= self.df['Ram'] >= min_ram\n",
    "        if min_ssd:\n",
    "            mask &= self.df['SSD'] >= min_ssd\n",
    "            \n",
    "        budget_df = self.df[mask].copy()\n",
    "        \n",
    "        if len(budget_df) == 0:\n",
    "            closest = self.df.iloc[(self.df['PredictedPrice'] - budget_inr).abs().argsort()[:5]]\n",
    "            print(f\"⚠️ No laptops within ₹{budget_inr:,} budget. Showing closest options:\")\n",
    "            return closest[['Company', 'TypeName', 'Ram', 'SSD', 'Weight', 'PredictedPrice']]\n",
    "        \n",
    "        # Calculate scores\n",
    "        budget_df['FeatureScore'] = self.calculate_score(weights, brand_prefs, cpu_prefs)\n",
    "        \n",
    "        # Price score (higher is better - cheaper laptops score higher)\n",
    "        budget_df['PriceScore'] = 1 - ((budget_df['PredictedPrice'] - budget_df['PredictedPrice'].min()) / \n",
    "                                      (budget_df['PredictedPrice'].max() - budget_df['PredictedPrice'].min()))\n",
    "        \n",
    "        # Combined score\n",
    "        budget_df['CombinedScore'] = (\n",
    "            (1 - price_importance) * budget_df['FeatureScore'] +\n",
    "            price_importance * budget_df['PriceScore']\n",
    "        )\n",
    "        \n",
    "        # Format INR prices\n",
    "        budget_df['Price_INR'] = budget_df['PredictedPrice'].apply(lambda x: f\"₹{x:,.2f}\")\n",
    "        \n",
    "        # Sort and return recommendations\n",
    "        recommendations = budget_df.sort_values(['CombinedScore', 'PredictedPrice'], \n",
    "                                              ascending=[False, True])\n",
    "        \n",
    "        return recommendations.head(top_n)[[\n",
    "            'Company', 'TypeName', 'Ram', 'SSD', 'Weight', 'Price_INR',\n",
    "            'FeatureScore', 'PriceScore', 'CombinedScore'\n",
    "        ]]\n",
    "\n",
    "# ====================== EXAMPLE USAGE FOR INDIAN MARKET ======================\n",
    "\n",
    "print(\"\\nTesting Indian market recommendation system...\")\n",
    "india_recommender = IndiaLaptopRecommender()\n",
    "\n",
    "# Example 1: Student laptop under ₹50,000\n",
    "print(\"\\nStudent laptop recommendations under ₹50,000:\")\n",
    "student_weights = {\n",
    "    'Ram': 0.3,\n",
    "    'SSD': 0.3,\n",
    "    'Weight': 0.2,\n",
    "    'Company': 0.2  # Trusted brands important for students\n",
    "}\n",
    "print(india_recommender.recommend(\n",
    "    budget_inr=50000,\n",
    "    weights=student_weights,\n",
    "    min_ram=8,\n",
    "    price_importance=0.5\n",
    "))\n",
    "\n",
    "# Example 2: Premium laptop under ₹1,00,000 with brand preference\n",
    "print(\"\\nPremium laptop recommendations under ₹1,00,000:\")\n",
    "premium_brands = {\n",
    "    'Apple': 1.5,\n",
    "    'Dell': 1.3,\n",
    "    'HP': 1.2\n",
    "}\n",
    "print(india_recommender.recommend(\n",
    "    budget_inr=100000,\n",
    "    brand_prefs=premium_brands,\n",
    "    min_ram=16,\n",
    "    min_ssd=512,\n",
    "    price_importance=0.2\n",
    "))\n",
    "\n",
    "# Example 3: Budget gaming laptop under ₹70,000\n",
    "print(\"\\nBudget gaming laptop under ₹70,000:\")\n",
    "gaming_weights = {\n",
    "    'Ram': 0.4,\n",
    "    'SSD': 0.3,\n",
    "    'Cpu brand': 0.3  # CPU important for gaming\n",
    "}\n",
    "gaming_cpus = {\n",
    "    'Intel Core i7': 1.5,\n",
    "    'Intel Core i5': 1.2,\n",
    "    'AMD Processor': 1.1\n",
    "}\n",
    "print(india_recommender.recommend(\n",
    "    budget_inr=70000,\n",
    "    weights=gaming_weights,\n",
    "    cpu_prefs=gaming_cpus,\n",
    "    min_ram=8,\n",
    "    min_ssd=256\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92263e53-3cfe-4840-a91e-c364368e8a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
