{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d275e8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "826126bb-ecec-4f2b-9436-21e0fddaef3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "\n",
      "Training custom Random Forest...\n",
      "\n",
      "Random Forest Performance:\n",
      "MSE: 0.1576\n",
      "MAE: 0.3223\n",
      "R² Score: 0.5910\n",
      "\n",
      "Training custom KNN...\n",
      "\n",
      "KNN Performance:\n",
      "MSE: 0.0704\n",
      "MAE: 0.1964\n",
      "R² Score: 0.8174\n",
      "\n",
      "Saving models...\n",
      "Saved successfully to laptop_models_full_custom.pkl ✅\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heapq\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.utils import resample\n",
    "from scipy.sparse import issparse\n",
    "import joblib\n",
    "\n",
    "# ====================== CUSTOM MODELS ======================\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, (pd.Series, pd.DataFrame)):\n",
    "            y = y.values\n",
    "            \n",
    "        self.tree_ = self._build_tree(X, y, depth=0)\n",
    "    \n",
    "    def _build_tree(self, X, y, depth):\n",
    "        num_samples = X.shape[0]\n",
    "        \n",
    "        # Stopping conditions\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or \\\n",
    "           num_samples < self.min_samples_split or \\\n",
    "           len(np.unique(y)) == 1:\n",
    "            return np.mean(y)\n",
    "\n",
    "        best_split = self._find_best_split(X, y)\n",
    "        if best_split is None:\n",
    "            return np.mean(y)\n",
    "        \n",
    "        left_indices = X[:, best_split['feature']] <= best_split['value']\n",
    "        right_indices = ~left_indices\n",
    "        \n",
    "        if np.sum(left_indices) == 0 or np.sum(right_indices) == 0:\n",
    "            return np.mean(y)\n",
    "        \n",
    "        left_tree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_tree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "        \n",
    "        return {\n",
    "            'feature': best_split['feature'],\n",
    "            'value': best_split['value'],\n",
    "            'left': left_tree,\n",
    "            'right': right_tree\n",
    "        }\n",
    "    \n",
    "    def _find_best_split(self, X, y):\n",
    "        best_split = None\n",
    "        best_mse = float('inf')\n",
    "        num_features = X.shape[1]\n",
    "\n",
    "        for feature in range(num_features):\n",
    "            unique_values = np.unique(X[:, feature])\n",
    "            split_points = np.percentile(unique_values, [25, 50, 75]) if len(unique_values) > 10 else unique_values\n",
    "            \n",
    "            for value in split_points:\n",
    "                left_indices = X[:, feature] <= value\n",
    "                right_indices = ~left_indices\n",
    "                \n",
    "                if np.sum(left_indices) < 2 or np.sum(right_indices) < 2:\n",
    "                    continue\n",
    "                \n",
    "                left_y = y[left_indices]\n",
    "                right_y = y[right_indices]\n",
    "                \n",
    "                mse = (np.var(left_y) * len(left_y) + np.var(right_y) * len(right_y)) / len(y)\n",
    "                \n",
    "                if mse < best_mse:\n",
    "                    best_split = {'feature': feature, 'value': value}\n",
    "                    best_mse = mse\n",
    "        \n",
    "        return best_split\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if issparse(X):\n",
    "            X = X.toarray()\n",
    "            \n",
    "        return np.array([self._predict(sample, self.tree_) for sample in X])\n",
    "    \n",
    "    def _predict(self, sample, tree):\n",
    "        if not isinstance(tree, dict):\n",
    "            return tree\n",
    "        \n",
    "        if sample[tree['feature']] <= tree['value']:\n",
    "            return self._predict(sample, tree['left'])\n",
    "        return self._predict(sample, tree['right'])\n",
    "\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, max_features='sqrt'):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.trees = []\n",
    "        self.feature_indices = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, (pd.Series, pd.DataFrame)):\n",
    "            y = y.values\n",
    "            \n",
    "        n_features = X.shape[1]\n",
    "        max_feats = int(np.sqrt(n_features)) if self.max_features == 'sqrt' else self.max_features\n",
    "        \n",
    "        for _ in range(self.n_estimators):\n",
    "            X_sample, y_sample = resample(X, y)\n",
    "            feature_idx = np.random.choice(n_features, max_feats, replace=False)\n",
    "            X_sub = X_sample[:, feature_idx]\n",
    "            \n",
    "            tree = DecisionTree(max_depth=self.max_depth)\n",
    "            tree.fit(X_sub, y_sample)\n",
    "            \n",
    "            self.trees.append(tree)\n",
    "            self.feature_indices.append(feature_idx)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if issparse(X):\n",
    "            X = X.toarray()\n",
    "            \n",
    "        all_preds = np.zeros((self.n_estimators, X.shape[0]))\n",
    "        \n",
    "        for i, (tree, feat_idx) in enumerate(zip(self.trees, self.feature_indices)):\n",
    "            X_sub = X[:, feat_idx]\n",
    "            all_preds[i] = tree.predict(X_sub)\n",
    "            \n",
    "        return np.mean(all_preds, axis=0)\n",
    "\n",
    "\n",
    "class CustomKNN:\n",
    "    def __init__(self, k=5, metric='cosine'):\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        \n",
    "    def _cosine_similarity(self, a, b):\n",
    "        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    \n",
    "    def _euclidean_distance(self, a, b):\n",
    "        return np.sqrt(np.sum((a - b) ** 2))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if issparse(X):\n",
    "            X = X.toarray()\n",
    "        self.X_train = X\n",
    "        # Convert y to numpy array if it's a pandas Series\n",
    "        self.y_train = y.values if isinstance(y, pd.Series) else y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if issparse(X):\n",
    "            X = X.toarray()\n",
    "            \n",
    "        predictions = []\n",
    "        for sample in X:\n",
    "            distances = []\n",
    "            if self.metric == 'cosine':\n",
    "                distances = [self._cosine_similarity(sample, x) for x in self.X_train]\n",
    "                # Get indices of k largest cosine similarities\n",
    "                neighbors = np.argpartition(distances, -self.k)[-self.k:]\n",
    "            else:\n",
    "                distances = [self._euclidean_distance(sample, x) for x in self.X_train]\n",
    "                # Get indices of k smallest distances\n",
    "                neighbors = np.argpartition(distances, self.k)[:self.k]\n",
    "            \n",
    "            # Get the average of the neighbors' values\n",
    "            prediction = np.mean(self.y_train[neighbors])\n",
    "            predictions.append(prediction)\n",
    "            \n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "# ====================== DATA PIPELINE ======================\n",
    "\n",
    "print(\"Loading and preprocessing data...\")\n",
    "df = pd.read_csv('laptop_data.csv')\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "# Data cleaning\n",
    "df[\"Ram\"] = df[\"Ram\"].str.replace(\"GB\", \"\").astype(\"int\")\n",
    "df[\"Weight\"] = df[\"Weight\"].str.replace(\"kg\", \"\").astype(\"float\")\n",
    "\n",
    "# Feature engineering\n",
    "df[\"Touchscreen\"] = df[\"ScreenResolution\"].apply(lambda x: 1 if \"Touchscreen\" in x else 0)\n",
    "df[\"Ips\"] = df[\"ScreenResolution\"].apply(lambda x: 1 if \"IPS\" in x else 0)\n",
    "\n",
    "# Process resolution\n",
    "temp = df[\"ScreenResolution\"].str.split(\"x\", n=1, expand=True)\n",
    "df[\"X_res\"] = temp[0].str.replace(',', '').str.findall(r'(\\d+\\.?\\d+)').apply(lambda x: x[0]).astype(int)\n",
    "df[\"Y_res\"] = temp[1].astype(int)\n",
    "df['ppi'] = (((df['X_res']**2) + (df['Y_res']**2))**0.5/df['Inches']).astype('float')\n",
    "df.drop(columns=[\"ScreenResolution\", \"X_res\", \"Y_res\", \"Inches\"], inplace=True)\n",
    "\n",
    "# Process CPU\n",
    "df['Cpu Name'] = df['Cpu'].apply(lambda x: \" \".join(x.split()[0:3]))\n",
    "def fetch_processor(text):\n",
    "    if text in ['Intel Core i7', 'Intel Core i5', 'Intel Core i3']:\n",
    "        return text\n",
    "    elif text.split()[0] == 'Intel':\n",
    "        return 'Other Intel Processor'\n",
    "    else:\n",
    "        return 'AMD Processor'\n",
    "df['Cpu brand'] = df['Cpu Name'].apply(fetch_processor)\n",
    "df.drop(columns=['Cpu', 'Cpu Name'], inplace=True)\n",
    "\n",
    "# Process Memory\n",
    "df['Memory'] = df['Memory'].astype(str).replace(r'\\.0', '', regex=True)\n",
    "df[\"Memory\"] = df[\"Memory\"].str.replace('GB', '').str.replace('TB', '000')\n",
    "new = df[\"Memory\"].str.split(\"+\", n=1, expand=True)\n",
    "df[\"first\"] = new[0].str.strip().str.replace(r'\\D', '', regex=True).astype(int)\n",
    "df[\"second\"] = new[1].fillna(\"0\").str.replace(r'\\D', '', regex=True).astype(int)\n",
    "df[\"HDD\"] = (df[\"first\"] * df[\"first\"].apply(lambda x: 1 if \"HDD\" in str(x) else 0)) + \\\n",
    "            (df[\"second\"] * df[\"second\"].apply(lambda x: 1 if \"HDD\" in str(x) else 0))\n",
    "df[\"SSD\"] = (df[\"first\"] * df[\"first\"].apply(lambda x: 1 if \"SSD\" in str(x) else 0)) + \\\n",
    "            (df[\"second\"] * df[\"second\"].apply(lambda x: 1 if \"SSD\" in str(x) else 0))\n",
    "df.drop(columns=['first', 'second', 'Memory'], inplace=True)\n",
    "\n",
    "# Process GPU\n",
    "df['Gpu brand'] = df['Gpu'].apply(lambda x: x.split()[0])\n",
    "df = df[df['Gpu brand'] != 'ARM']\n",
    "df.drop(columns=['Gpu'], inplace=True)\n",
    "\n",
    "# Process OS\n",
    "def cat_os(inp):\n",
    "    if inp in ['Windows 10', 'Windows 7', 'Windows 10 S']:\n",
    "        return 'Windows'\n",
    "    elif inp in ['macOS', 'Mac OS X']:\n",
    "        return 'Mac'\n",
    "    else:\n",
    "        return 'Others/No OS/Linux'\n",
    "df['os'] = df['OpSys'].apply(cat_os)\n",
    "df.drop(columns=['OpSys'], inplace=True)\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=['Price'])\n",
    "y = np.log(df['Price'])\n",
    "\n",
    "# Preprocessing pipeline\n",
    "cat_cols = ['Company', 'TypeName', 'Cpu brand', 'Gpu brand', 'os']\n",
    "num_cols = ['Ram', 'Weight', 'Touchscreen', 'Ips', 'ppi', 'HDD', 'SSD']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "])\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Transform\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "if issparse(X_train_transformed):\n",
    "    X_train_transformed = X_train_transformed.toarray()\n",
    "if issparse(X_test_transformed):\n",
    "    X_test_transformed = X_test_transformed.toarray()\n",
    "\n",
    "# ====================== MODEL TRAINING ======================\n",
    "\n",
    "print(\"\\nTraining custom Random Forest...\")\n",
    "rf_model = RandomForest(n_estimators=100, max_depth=10, max_features='sqrt')\n",
    "rf_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "y_pred_rf = rf_model.predict(X_test_transformed)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"\\nRandom Forest Performance:\")\n",
    "print(f\"MSE: {mse_rf:.4f}\")\n",
    "print(f\"MAE: {mae_rf:.4f}\")\n",
    "print(f\"R² Score: {r2_rf:.4f}\")\n",
    "\n",
    "print(\"\\nTraining custom KNN...\")\n",
    "knn_model = CustomKNN(k=5, metric='cosine')\n",
    "knn_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Evaluate KNN\n",
    "y_pred_knn = knn_model.predict(X_test_transformed)\n",
    "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
    "mae_knn = mean_absolute_error(y_test, y_pred_knn)\n",
    "r2_knn = r2_score(y_test, y_pred_knn)\n",
    "\n",
    "print(\"\\nKNN Performance:\")\n",
    "print(f\"MSE: {mse_knn:.4f}\")\n",
    "print(f\"MAE: {mae_knn:.4f}\")\n",
    "print(f\"R² Score: {r2_knn:.4f}\")\n",
    "\n",
    "# ====================== SAVE MODELS ======================\n",
    "\n",
    "print(\"\\nSaving models...\")\n",
    "joblib.dump({\n",
    "    'df': df,\n",
    "    'preprocessor': preprocessor,\n",
    "    'random_forest': rf_model,\n",
    "    'knn': knn_model\n",
    "}, 'laptop_models_full_custom.pkl')\n",
    "\n",
    "print(\"Saved successfully to laptop_models_full_custom.pkl ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d57f7d5-0f8d-4042-8d5d-436d544cb1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "\n",
      "Training custom Random Forest...\n",
      "\n",
      "Random Forest Performance:\n",
      "MSE: 0.1512\n",
      "MAE: 0.3163\n",
      "R² Score: 0.6076\n",
      "\n",
      "Training custom KNN (Price Priority)...\n",
      "\n",
      "KNN Performance:\n",
      "MSE: 0.0800\n",
      "MAE: 0.2106\n",
      "R² Score: 0.7925\n",
      "\n",
      "Saving models...\n",
      "Saved successfully to laptop_models_full_custom_2.pkl ✅\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heapq\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.utils import resample\n",
    "from scipy.sparse import issparse\n",
    "import joblib\n",
    "\n",
    "# ====================== CUSTOM MODELS ======================\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, (pd.Series, pd.DataFrame)):\n",
    "            y = y.values\n",
    "            \n",
    "        self.tree_ = self._build_tree(X, y, depth=0)\n",
    "    \n",
    "    def _build_tree(self, X, y, depth):\n",
    "        num_samples = X.shape[0]\n",
    "        \n",
    "        # Stopping conditions\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or \\\n",
    "           num_samples < self.min_samples_split or \\\n",
    "           len(np.unique(y)) == 1:\n",
    "            return np.mean(y)\n",
    "\n",
    "        best_split = self._find_best_split(X, y)\n",
    "        if best_split is None:\n",
    "            return np.mean(y)\n",
    "        \n",
    "        left_indices = X[:, best_split['feature']] <= best_split['value']\n",
    "        right_indices = ~left_indices\n",
    "        \n",
    "        if np.sum(left_indices) == 0 or np.sum(right_indices) == 0:\n",
    "            return np.mean(y)\n",
    "        \n",
    "        left_tree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_tree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "        \n",
    "        return {\n",
    "            'feature': best_split['feature'],\n",
    "            'value': best_split['value'],\n",
    "            'left': left_tree,\n",
    "            'right': right_tree\n",
    "        }\n",
    "    \n",
    "    def _find_best_split(self, X, y):\n",
    "        best_split = None\n",
    "        best_mse = float('inf')\n",
    "        num_features = X.shape[1]\n",
    "\n",
    "        for feature in range(num_features):\n",
    "            unique_values = np.unique(X[:, feature])\n",
    "            split_points = np.percentile(unique_values, [25, 50, 75]) if len(unique_values) > 10 else unique_values\n",
    "            \n",
    "            for value in split_points:\n",
    "                left_indices = X[:, feature] <= value\n",
    "                right_indices = ~left_indices\n",
    "                \n",
    "                if np.sum(left_indices) < 2 or np.sum(right_indices) < 2:\n",
    "                    continue\n",
    "                \n",
    "                left_y = y[left_indices]\n",
    "                right_y = y[right_indices]\n",
    "                \n",
    "                mse = (np.var(left_y) * len(left_y) + np.var(right_y) * len(right_y)) / len(y)\n",
    "                \n",
    "                if mse < best_mse:\n",
    "                    best_split = {'feature': feature, 'value': value}\n",
    "                    best_mse = mse\n",
    "        \n",
    "        return best_split\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if issparse(X):\n",
    "            X = X.toarray()\n",
    "            \n",
    "        return np.array([self._predict(sample, self.tree_) for sample in X])\n",
    "    \n",
    "    def _predict(self, sample, tree):\n",
    "        if not isinstance(tree, dict):\n",
    "            return tree\n",
    "        \n",
    "        if sample[tree['feature']] <= tree['value']:\n",
    "            return self._predict(sample, tree['left'])\n",
    "        return self._predict(sample, tree['right'])\n",
    "\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, max_features='sqrt'):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.trees = []\n",
    "        self.feature_indices = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, (pd.Series, pd.DataFrame)):\n",
    "            y = y.values\n",
    "            \n",
    "        n_features = X.shape[1]\n",
    "        max_feats = int(np.sqrt(n_features)) if self.max_features == 'sqrt' else self.max_features\n",
    "        \n",
    "        for _ in range(self.n_estimators):\n",
    "            X_sample, y_sample = resample(X, y)\n",
    "            feature_idx = np.random.choice(n_features, max_feats, replace=False)\n",
    "            X_sub = X_sample[:, feature_idx]\n",
    "            \n",
    "            tree = DecisionTree(max_depth=self.max_depth)\n",
    "            tree.fit(X_sub, y_sample)\n",
    "            \n",
    "            self.trees.append(tree)\n",
    "            self.feature_indices.append(feature_idx)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if issparse(X):\n",
    "            X = X.toarray()\n",
    "            \n",
    "        all_preds = np.zeros((self.n_estimators, X.shape[0]))\n",
    "        \n",
    "        for i, (tree, feat_idx) in enumerate(zip(self.trees, self.feature_indices)):\n",
    "            X_sub = X[:, feat_idx]\n",
    "            all_preds[i] = tree.predict(X_sub)\n",
    "            \n",
    "        return np.mean(all_preds, axis=0)\n",
    "\n",
    "\n",
    "# ====================== UPDATED KNN WITH PRICE PRIORITY ======================\n",
    "\n",
    "class CustomKNN:\n",
    "    def __init__(self, k=5, metric='cosine', price_weight=2.0):\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "        self.price_weight = price_weight\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        \n",
    "    def _cosine_similarity(self, a, b):\n",
    "        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    \n",
    "    def _euclidean_distance(self, a, b):\n",
    "        return np.sqrt(np.sum((a - b) ** 2))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if issparse(X):\n",
    "            X = X.toarray()\n",
    "        \n",
    "        prices = np.array(y).reshape(-1, 1)\n",
    "        self.X_train = np.hstack((X, prices * self.price_weight))\n",
    "        self.y_train = np.array(y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if issparse(X):\n",
    "            X = X.toarray()\n",
    "        \n",
    "        predictions = []\n",
    "        avg_price = np.mean(self.y_train)\n",
    "        \n",
    "        for sample in X:\n",
    "            sample_with_price = np.hstack((sample, avg_price * self.price_weight))\n",
    "            \n",
    "            if self.metric == 'cosine':\n",
    "                distances = [self._cosine_similarity(sample_with_price, x) for x in self.X_train]\n",
    "                neighbors = np.argpartition(distances, -self.k)[-self.k:]\n",
    "            else:\n",
    "                distances = [self._euclidean_distance(sample_with_price, x) for x in self.X_train]\n",
    "                neighbors = np.argpartition(distances, self.k)[:self.k]\n",
    "            \n",
    "            prediction = np.mean(self.y_train[neighbors])\n",
    "            predictions.append(prediction)\n",
    "        \n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def recommend(self, sample, n_recommendations=5):\n",
    "        avg_price = np.mean(self.y_train)\n",
    "        sample_with_price = np.hstack((sample, avg_price * self.price_weight))\n",
    "        \n",
    "        if self.metric == 'cosine':\n",
    "            similarities = [self._cosine_similarity(sample_with_price, x) for x in self.X_train]\n",
    "            top_indices = np.argsort(similarities)[::-1][:n_recommendations]\n",
    "        else:\n",
    "            distances = [self._euclidean_distance(sample_with_price, x) for x in self.X_train]\n",
    "            top_indices = np.argsort(distances)[:n_recommendations]\n",
    "        \n",
    "        return top_indices\n",
    "\n",
    "\n",
    "# ====================== DATA PIPELINE ======================\n",
    "\n",
    "print(\"Loading and preprocessing data...\")\n",
    "df = pd.read_csv('laptop_data.csv')\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "df[\"Ram\"] = df[\"Ram\"].str.replace(\"GB\", \"\").astype(\"int\")\n",
    "df[\"Weight\"] = df[\"Weight\"].str.replace(\"kg\", \"\").astype(\"float\")\n",
    "\n",
    "df[\"Touchscreen\"] = df[\"ScreenResolution\"].apply(lambda x: 1 if \"Touchscreen\" in x else 0)\n",
    "df[\"Ips\"] = df[\"ScreenResolution\"].apply(lambda x: 1 if \"IPS\" in x else 0)\n",
    "\n",
    "temp = df[\"ScreenResolution\"].str.split(\"x\", n=1, expand=True)\n",
    "df[\"X_res\"] = temp[0].str.replace(',', '').str.findall(r'(\\d+\\.?\\d+)').apply(lambda x: x[0]).astype(int)\n",
    "df[\"Y_res\"] = temp[1].astype(int)\n",
    "df['ppi'] = (((df['X_res']**2) + (df['Y_res']**2))**0.5/df['Inches']).astype('float')\n",
    "df.drop(columns=[\"ScreenResolution\", \"X_res\", \"Y_res\", \"Inches\"], inplace=True)\n",
    "\n",
    "df['Cpu Name'] = df['Cpu'].apply(lambda x: \" \".join(x.split()[0:3]))\n",
    "def fetch_processor(text):\n",
    "    if text in ['Intel Core i7', 'Intel Core i5', 'Intel Core i3']:\n",
    "        return text\n",
    "    elif text.split()[0] == 'Intel':\n",
    "        return 'Other Intel Processor'\n",
    "    else:\n",
    "        return 'AMD Processor'\n",
    "df['Cpu brand'] = df['Cpu Name'].apply(fetch_processor)\n",
    "df.drop(columns=['Cpu', 'Cpu Name'], inplace=True)\n",
    "\n",
    "df['Memory'] = df['Memory'].astype(str).replace(r'\\.0', '', regex=True)\n",
    "df[\"Memory\"] = df[\"Memory\"].str.replace('GB', '').str.replace('TB', '000')\n",
    "new = df[\"Memory\"].str.split(\"+\", n=1, expand=True)\n",
    "df[\"first\"] = new[0].str.strip().str.replace(r'\\D', '', regex=True).astype(int)\n",
    "df[\"second\"] = new[1].fillna(\"0\").str.replace(r'\\D', '', regex=True).astype(int)\n",
    "df[\"HDD\"] = (df[\"first\"] * df[\"first\"].apply(lambda x: 1 if \"HDD\" in str(x) else 0)) + \\\n",
    "            (df[\"second\"] * df[\"second\"].apply(lambda x: 1 if \"HDD\" in str(x) else 0))\n",
    "df[\"SSD\"] = (df[\"first\"] * df[\"first\"].apply(lambda x: 1 if \"SSD\" in str(x) else 0)) + \\\n",
    "            (df[\"second\"] * df[\"second\"].apply(lambda x: 1 if \"SSD\" in str(x) else 0))\n",
    "df.drop(columns=['first', 'second', 'Memory'], inplace=True)\n",
    "\n",
    "df['Gpu brand'] = df['Gpu'].apply(lambda x: x.split()[0])\n",
    "df = df[df['Gpu brand'] != 'ARM']\n",
    "df.drop(columns=['Gpu'], inplace=True)\n",
    "\n",
    "def cat_os(inp):\n",
    "    if inp in ['Windows 10', 'Windows 7', 'Windows 10 S']:\n",
    "        return 'Windows'\n",
    "    elif inp in ['macOS', 'Mac OS X']:\n",
    "        return 'Mac'\n",
    "    else:\n",
    "        return 'Others/No OS/Linux'\n",
    "df['os'] = df['OpSys'].apply(cat_os)\n",
    "df.drop(columns=['OpSys'], inplace=True)\n",
    "\n",
    "X = df.drop(columns=['Price'])\n",
    "y = np.log(df['Price'])\n",
    "\n",
    "cat_cols = ['Company', 'TypeName', 'Cpu brand', 'Gpu brand', 'os']\n",
    "num_cols = ['Ram', 'Weight', 'Touchscreen', 'Ips', 'ppi', 'HDD', 'SSD']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "if issparse(X_train_transformed):\n",
    "    X_train_transformed = X_train_transformed.toarray()\n",
    "if issparse(X_test_transformed):\n",
    "    X_test_transformed = X_test_transformed.toarray()\n",
    "\n",
    "# ====================== MODEL TRAINING ======================\n",
    "\n",
    "print(\"\\nTraining custom Random Forest...\")\n",
    "rf_model = RandomForest(n_estimators=100, max_depth=10, max_features='sqrt')\n",
    "rf_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test_transformed)\n",
    "print(\"\\nRandom Forest Performance:\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"R² Score: {r2_score(y_test, y_pred_rf):.4f}\")\n",
    "\n",
    "print(\"\\nTraining custom KNN (Price Priority)...\")\n",
    "knn_model = CustomKNN(k=5, metric='cosine', price_weight=3.0)\n",
    "knn_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred_knn = knn_model.predict(X_test_transformed)\n",
    "print(\"\\nKNN Performance:\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred_knn):.4f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_knn):.4f}\")\n",
    "print(f\"R² Score: {r2_score(y_test, y_pred_knn):.4f}\")\n",
    "\n",
    "# ====================== SAVE MODELS ======================\n",
    "\n",
    "print(\"\\nSaving models...\")\n",
    "joblib.dump({\n",
    "    'df': df,\n",
    "    'preprocessor': preprocessor,\n",
    "    'random_forest': rf_model,\n",
    "    'knn': knn_model\n",
    "}, 'laptop_models_full_custom_2.pkl')\n",
    "\n",
    "print(\"Saved successfully to laptop_models_full_custom_2.pkl ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51c4992-cda6-463e-81b0-029341cc4e19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
